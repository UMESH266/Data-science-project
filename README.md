# Data-science-project
Basic end to end Data Science project 

1. Environment : Create virtual environment to maintain necessary dependencies (Libraries, packages, python version).

2. requirements : Create requirements.txt file and add the libraries required for the project.

3. template.py : Generic project structure code.

4. logging setup: Create logging functionality inside src/__init__.py to track and debug execution of code.

5. common utils : define common utility functions such as save pickle file, load pickle files etc.

### Workflows - ML pipeline

1. Data Ingestion
2. Data validation
3. Data Transformation
4. Model Trainer
5. Model evaluation

Modular coding - 

## Workflows 

1. Update config.yaml - Update input details required for data ingestion from different sources
2. Update schema.yaml - Update in data validation
3. Update params.yaml - Used for providing parameters to model
4. Update the entity - Creation of dataclasses 
5. Update the configuration manager in src config - Createion root directory, file paths to etc related to the task
6. Update the components - 
7. Update the pipeline -
8. Update the main.py -